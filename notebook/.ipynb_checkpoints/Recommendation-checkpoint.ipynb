{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/pickle/podcasts_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df[['title', 'producer', 'genre', 'description', 'episodes', 'reviews']].agg(' '.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['producer', 'rating', 'num_ratings', 'num_episodes', 'description',\n",
    "                 'link', 'episodes', 'reviews'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subs_len'] = df.apply(lambda row: len(row.subs), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>subs</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Green Eggs and Dan</td>\n",
       "      <td>Arts</td>\n",
       "      <td>[Point of Origin, Cal's Week in Review]</td>\n",
       "      <td>Green Eggs and Dan The Podglomerate Arts Takin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Audio Poem of the Day</td>\n",
       "      <td>Arts</td>\n",
       "      <td>[The New Yorker: Poetry, The New Yorker: The W...</td>\n",
       "      <td>Audio Poem of the Day Poetry Foundation Arts A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title genre  \\\n",
       "0     Green Eggs and Dan  Arts   \n",
       "1  Audio Poem of the Day  Arts   \n",
       "\n",
       "                                                subs  \\\n",
       "0            [Point of Origin, Cal's Week in Review]   \n",
       "1  [The New Yorker: Poetry, The New Yorker: The W...   \n",
       "\n",
       "                                                text  \n",
       "0  Green Eggs and Dan The Podglomerate Arts Takin...  \n",
       "1  Audio Poem of the Day Poetry Foundation Arts A...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "add_stops = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "             'january', 'february', 'march', 'april', 'may', 'june', 'im', 'ive',\n",
    "             'july', 'august', 'september', 'october', 'november', 'december',\n",
    "             'nan', 'podcast', 'podcasts', 'every', 'new', 'weekly', 'week', \n",
    "             'stories', 'story', 'episode', 'episodes', 'listen', 'us', \"'s\", 'host', 'hosted', 'join']\n",
    "for i in add_stops:\n",
    "    stopwords.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\s\\w]+', '', text)\n",
    "    text = re.sub(r\"\\S+\\.org\\S+\", \"\", text)\n",
    "    text = re.sub(r\"\\S+\\.net\\S+\", \"\", text)\n",
    "    text = re.sub(r\"\\S+\\.edu\\S+\", \"\", text)\n",
    "    text = re.sub(r\"\\S+\\.gov\\S+\", \"\", text)\n",
    "    tokenized_text = nltk.word_tokenize(text)\n",
    "    new_tokenized = []\n",
    "    for i in tokenized_text:\n",
    "        if i not in stopwords and len(i) != 1:\n",
    "            new_tokenized.append(lemmatizer.lemmatize(i))\n",
    "    return(' '.join(new_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text = df.text.map(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>subs</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Green Eggs and Dan</td>\n",
       "      <td>Arts</td>\n",
       "      <td>[Point of Origin, Cal's Week in Review]</td>\n",
       "      <td>green egg dan podglomerate art taking look eat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Audio Poem of the Day</td>\n",
       "      <td>Arts</td>\n",
       "      <td>[The New Yorker: Poetry, The New Yorker: The W...</td>\n",
       "      <td>audio poem day poetry foundation art audio rec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title genre  \\\n",
       "0     Green Eggs and Dan  Arts   \n",
       "1  Audio Poem of the Day  Arts   \n",
       "\n",
       "                                                subs  \\\n",
       "0            [Point of Origin, Cal's Week in Review]   \n",
       "1  [The New Yorker: Poetry, The New Yorker: The W...   \n",
       "\n",
       "                                                text  \n",
       "0  green egg dan podglomerate art taking look eat...  \n",
       "1  audio poem day poetry foundation art audio rec...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = list(df[df.subs_len != 0].sample(5).title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(matrix):\n",
    "    for i in tests:\n",
    "        print('\\033[1m' + \"Given:\" + '\\033[0m', i)\n",
    "        index = df.loc[df.title == i].index[0]\n",
    "        print('\\033[1m' + \"Given genre:\" + '\\033[0m', df.iloc[index]['genre'])\n",
    "        array = list(enumerate(matrix[index]))\n",
    "        sorted_array = sorted(array, key=lambda x:x[1], reverse=True)\n",
    "        recs = []\n",
    "        genres = []\n",
    "        for j in range(6):\n",
    "            if j == 0:\n",
    "                continue\n",
    "            rec_title = df.iloc[sorted_array[j][0]]['title']\n",
    "            recs.append(rec_title)\n",
    "            rec_genre = df.iloc[sorted_array[j][0]]['genre']\n",
    "            genres.append(rec_genre)\n",
    "        print('\\033[1m' + \"Top 5 recommendations:\" + '\\033[0m')\n",
    "        print(recs)\n",
    "        print('\\033[1m' + \"Top 5 recommendations' genre:\" + '\\033[0m')\n",
    "        print(genres)\n",
    "        print('\\033[1m' + \"Subscribers also subscribes to according to Apple Podcasts:\" + '\\033[0m')\n",
    "        for k in df.loc[df.title == i].subs:\n",
    "            substo = k\n",
    "        print(substo)\n",
    "        correct  = 0\n",
    "        for l in recs:\n",
    "            correct = correct + 1 if l in substo else correct\n",
    "        print('\\033[1m', correct , \"out of 5 are accurate\" + '\\033[0m'+ \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer (Bag-of-words) + Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "bow_matrix = cv.fit_transform(df.text)\n",
    "bow_cos_sim = cosine_similarity(bow_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mGiven:\u001b[0m Red Ball\n",
      "\u001b[1mGiven genre:\u001b[0m True Crime\n",
      "\u001b[1mTop 5 recommendations:\u001b[0m\n",
      "['CounterClock', 'Up and Vanished', 'Crime Junkie', 'O.C. Swingers', 'True Crime Chronicles']\n",
      "\u001b[1mTop 5 recommendations' genre:\u001b[0m\n",
      "['True Crime', 'True Crime', 'True Crime', 'True Crime', 'True Crime']\n",
      "\u001b[1mSubscribers also subscribes to according to Apple Podcasts:\u001b[0m\n",
      "['CounterClock', 'Full Body Chills', 'Murder in Oregon', 'Radio Rental', 'Your Own Backyard', 'Detective Trapp', 'Supernatural with Ashley Flowers', 'Urge to Kill', 'Dateline NBC', 'Morbid: A True Crime Podcast', 'Blood Ties', 'The Thing About Pam', 'Bad Batch']\n",
      "\u001b[1m 1 out of 5 are accurate\u001b[0m\n",
      "\n",
      "\u001b[1mGiven:\u001b[0m MCAT Basics (from MedSchoolCoach‪)‬\n",
      "\u001b[1mGiven genre:\u001b[0m Science\n",
      "\u001b[1mTop 5 recommendations:\u001b[0m\n",
      "['The MCAT Podcast', 'OT Exam Prepper', \"It's Been a Minute with Sam Sanders\", 'Physician Assistant Exam Review', 'Becoming Something with Jonathan Pokluda']\n",
      "\u001b[1mTop 5 recommendations' genre:\u001b[0m\n",
      "['Science', 'Arts', 'Society & Culture', 'Science', 'Religion & Spirituality']\n",
      "\u001b[1mSubscribers also subscribes to according to Apple Podcasts:\u001b[0m\n",
      "['The MCAT Podcast', 'All Access: Med School Admissions']\n",
      "\u001b[1m 1 out of 5 are accurate\u001b[0m\n",
      "\n",
      "\u001b[1mGiven:\u001b[0m Be you, Unapologetically‪.‬\n",
      "\u001b[1mGiven genre:\u001b[0m Business\n",
      "\u001b[1mTop 5 recommendations:\u001b[0m\n",
      "['Girls Night with Stephanie May Wilson', 'Self Love Babe', 'Earn Your Happy', 'Love Over Addiction', 'Better Than Happy']\n",
      "\u001b[1mTop 5 recommendations' genre:\u001b[0m\n",
      "['Religion & Spirituality', 'Education', 'Education', 'Health & Fitness', 'Education']\n",
      "\u001b[1mSubscribers also subscribes to according to Apple Podcasts:\u001b[0m\n",
      "['EmpowerHER', '6 Figure Influencer']\n",
      "\u001b[1m 0 out of 5 are accurate\u001b[0m\n",
      "\n",
      "\u001b[1mGiven:\u001b[0m Heather Dubrow's World\n",
      "\u001b[1mGiven genre:\u001b[0m Society & Culture\n",
      "\u001b[1mTop 5 recommendations:\u001b[0m\n",
      "['Juicy Scoop with Heather McDonald', 'How Did This Get Played\\u202a?\\u202c', 'Now & Then', 'Give Them Lala ... with Randall', 'Absolutely Not']\n",
      "\u001b[1mTop 5 recommendations' genre:\u001b[0m\n",
      "['Comedy', 'Comedy', 'History', 'Society & Culture', 'Comedy']\n",
      "\u001b[1mSubscribers also subscribes to according to Apple Podcasts:\u001b[0m\n",
      "[\"Bravo TV's The Daily Dish\", 'Reality Life with Kate Casey', 'House of Kim with Kim Zolciak', 'Two Judgey Girls']\n",
      "\u001b[1m 0 out of 5 are accurate\u001b[0m\n",
      "\n",
      "\u001b[1mGiven:\u001b[0m Yo, Is This Racist‪?‬\n",
      "\u001b[1mGiven genre:\u001b[0m Comedy\n",
      "\u001b[1mTop 5 recommendations:\u001b[0m\n",
      "['Black History for White People', 'Everything is Fine', \"The World's First Podcast with Erin & Sara Foster\", 'Code Switch', 'The Brilliant Idiots']\n",
      "\u001b[1mTop 5 recommendations' genre:\u001b[0m\n",
      "['History', 'Arts', 'Society & Culture', 'News', 'Comedy']\n",
      "\u001b[1mSubscribers also subscribes to according to Apple Podcasts:\u001b[0m\n",
      "['Las Culturistas with Matt Rogers and Bowen Yang', \"Why Won't You Date Me? with Nicole Byer\", 'The Bechdel Cast', 'Best Friends with Nicole Byer and Sasheer Zamata', 'Still Processing', 'Unspooled', 'Blank Check with Griffin & David', 'Who? Weekly']\n",
      "\u001b[1m 0 out of 5 are accurate\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_recommendations(bow_cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
