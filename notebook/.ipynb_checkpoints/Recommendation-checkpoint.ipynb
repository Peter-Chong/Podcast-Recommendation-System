{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/pickle/podcasts_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df[['title', 'producer', 'genre', 'description', 'episodes', 'reviews']].agg(' '.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['producer', 'rating', 'num_ratings', 'num_episodes', 'description',\n",
    "                 'link', 'episodes', 'reviews'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subs_len'] = df.apply(lambda row: len(row.subs), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>subs</th>\n",
       "      <th>text</th>\n",
       "      <th>subs_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Green Eggs and Dan</td>\n",
       "      <td>Arts</td>\n",
       "      <td>[Point of Origin, Cal's Week in Review]</td>\n",
       "      <td>Green Eggs and Dan The Podglomerate Arts Takin...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Audio Poem of the Day</td>\n",
       "      <td>Arts</td>\n",
       "      <td>[The New Yorker: Poetry, The New Yorker: The W...</td>\n",
       "      <td>Audio Poem of the Day Poetry Foundation Arts A...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title genre  \\\n",
       "0     Green Eggs and Dan  Arts   \n",
       "1  Audio Poem of the Day  Arts   \n",
       "\n",
       "                                                subs  \\\n",
       "0            [Point of Origin, Cal's Week in Review]   \n",
       "1  [The New Yorker: Poetry, The New Yorker: The W...   \n",
       "\n",
       "                                                text  subs_len  \n",
       "0  Green Eggs and Dan The Podglomerate Arts Takin...         2  \n",
       "1  Audio Poem of the Day Poetry Foundation Arts A...         5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "add_stops = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "             'january', 'february', 'march', 'april', 'may', 'june', 'im', 'ive',\n",
    "             'july', 'august', 'september', 'october', 'november', 'december',\n",
    "             'nan', 'podcast', 'podcasts', 'every', 'new', 'weekly', 'week', \n",
    "             'stories', 'story', 'episode', 'episodes', 'listen', 'us', \"'s\", 'host', 'hosted', 'join']\n",
    "for i in add_stops:\n",
    "    stopwords.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\s\\w]+', '', text)\n",
    "    text = re.sub(r\"\\S+\\.org\\S+\", \"\", text)\n",
    "    text = re.sub(r\"\\S+\\.net\\S+\", \"\", text)\n",
    "    text = re.sub(r\"\\S+\\.edu\\S+\", \"\", text)\n",
    "    text = re.sub(r\"\\S+\\.gov\\S+\", \"\", text)\n",
    "    tokenized_text = nltk.word_tokenize(text)\n",
    "    new_tokenized = []\n",
    "    for i in tokenized_text:\n",
    "        if i not in stopwords and len(i) != 1:\n",
    "            new_tokenized.append(lemmatizer.lemmatize(i))\n",
    "    return(' '.join(new_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text = df.text.map(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>subs</th>\n",
       "      <th>text</th>\n",
       "      <th>subs_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Green Eggs and Dan</td>\n",
       "      <td>Arts</td>\n",
       "      <td>[Point of Origin, Cal's Week in Review]</td>\n",
       "      <td>green egg dan podglomerate art taking look eat...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Audio Poem of the Day</td>\n",
       "      <td>Arts</td>\n",
       "      <td>[The New Yorker: Poetry, The New Yorker: The W...</td>\n",
       "      <td>audio poem day poetry foundation art audio rec...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title genre  \\\n",
       "0     Green Eggs and Dan  Arts   \n",
       "1  Audio Poem of the Day  Arts   \n",
       "\n",
       "                                                subs  \\\n",
       "0            [Point of Origin, Cal's Week in Review]   \n",
       "1  [The New Yorker: Poetry, The New Yorker: The W...   \n",
       "\n",
       "                                                text  subs_len  \n",
       "0  green egg dan podglomerate art taking look eat...         2  \n",
       "1  audio poem day poetry foundation art audio rec...         5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = list(df[df.subs_len != 0].sample(3).title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(matrix):\n",
    "    for i in tests:\n",
    "        print('\\033[1m' + \"Given:\" + '\\033[0m', i)\n",
    "        index = df.loc[df.title == i].index[0]\n",
    "        print('\\033[1m' + \"Given genre:\" + '\\033[0m', df.iloc[index]['genre'])\n",
    "        array = list(enumerate(matrix[index]))\n",
    "        sorted_array = sorted(array, key=lambda x:x[1], reverse=True)\n",
    "        recs = []\n",
    "        genres = []\n",
    "        for j in range(6):\n",
    "            if j == 0:\n",
    "                continue\n",
    "            rec_title = df.iloc[sorted_array[j][0]]['title']\n",
    "            recs.append(rec_title)\n",
    "            rec_genre = df.iloc[sorted_array[j][0]]['genre']\n",
    "            genres.append(rec_genre)\n",
    "        print('\\033[1m' + \"Top 5 recommendations:\" + '\\033[0m')\n",
    "        print(recs)\n",
    "        print('\\033[1m' + \"Top 5 recommendations' genre:\" + '\\033[0m')\n",
    "        print(genres)\n",
    "        print('\\033[1m' + \"Subscribers also subscribes to according to Apple Podcasts:\" + '\\033[0m')\n",
    "        for k in df.loc[df.title == i].subs:\n",
    "            substo = k\n",
    "        print(substo)\n",
    "        correct  = 0\n",
    "        for l in recs:\n",
    "            correct = correct + 1 if l in substo else correct\n",
    "        print('\\033[1m', correct , \"out of 5 are accurate\" + '\\033[0m'+ \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer (Bag-of-words) + Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CountVectorizer(data):\n",
    "    bigset = set()\n",
    "    for sent in data:\n",
    "        for word in sent.split(' '):\n",
    "            bigset.add(word)\n",
    "    vocab = {}\n",
    "    for index, word in enumerate(sorted(list(bigset))):\n",
    "        vocab[word] = index\n",
    "    row, col, val = [],[],[]\n",
    "    for idx, sentence in enumerate(data):\n",
    "        count_word = dict(Counter(sentence.split(' ')))\n",
    "        for word, count in count_word.items():\n",
    "            col_index = vocab.get(word)\n",
    "            if col_index >= 0:\n",
    "                row.append(idx)\n",
    "                col.append(col_index)\n",
    "                val.append(count)\n",
    "    return csr_matrix((val, (row, col)), shape=(len(data), len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_matrix = CountVectorizer(df.text)\n",
    "bow_cos_sim = cosine_similarity(bow_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mGiven:\u001b[0m Joyce Meyer Ministries TV Podcast\n",
      "\u001b[1mGiven genre:\u001b[0m Religion & Spirituality\n",
      "\u001b[1mTop 5 recommendations:\u001b[0m\n",
      "['Joyce Meyer Enjoying Everyday Life® TV Audio Podcast', 'Joyce Meyer Radio Podcast', \"Joyce Meyer's Talk It Out Podcast\", \"The Potter's House At One LA\", 'Equip and Empower with Christine Caine']\n",
      "\u001b[1mTop 5 recommendations' genre:\u001b[0m\n",
      "['Religion & Spirituality', 'Religion & Spirituality', 'Religion & Spirituality', 'Religion & Spirituality', 'Religion & Spirituality']\n",
      "\u001b[1mSubscribers also subscribes to according to Apple Podcasts:\u001b[0m\n",
      "['Joyce Meyer Enjoying Everyday Life® TV Audio Podcast', 'Joyce Meyer Radio Podcast', 'Joel Osteen Podcast', \"The Potter's Touch on Lightsource.com\", \"Pastor Rick's Daily Hope\", 'Elevation with Steven Furtick', 'Joel Osteen Podcast', 'Jesus Calling: Stories of Faith', 'Your Move with Andy Stanley Podcast', 'Bethel Church Sermon of the Week', 'The Proverbs 31 Ministries Podcast', '1 Year Daily Audio Bible', 'Transformation Church', 'Craig Groeschel Leadership Podcast']\n",
      "\u001b[1m 2 out of 5 are accurate\u001b[0m\n",
      "\n",
      "\u001b[1mGiven:\u001b[0m Heaving Bosoms: A Romance Novel Podcast\n",
      "\u001b[1mGiven genre:\u001b[0m Arts\n",
      "\u001b[1mTop 5 recommendations:\u001b[0m\n",
      "['Bookmarks', 'Read Me Romance', 'One Great Book', \"Sarah's Bookshelves Live\", 'What Should I Read Next\\u202a?\\u202c']\n",
      "\u001b[1mTop 5 recommendations' genre:\u001b[0m\n",
      "['Arts', 'Arts', 'Arts', 'Arts', 'Arts']\n",
      "\u001b[1mSubscribers also subscribes to according to Apple Podcasts:\u001b[0m\n",
      "['Fated Mates - A Romance Novel Podcast', 'Read Me Romance']\n",
      "\u001b[1m 1 out of 5 are accurate\u001b[0m\n",
      "\n",
      "\u001b[1mGiven:\u001b[0m Let's Talk About Myths, Baby! A Greek & Roman Mythology Podcast\n",
      "\u001b[1mGiven genre:\u001b[0m Arts\n",
      "\u001b[1mTop 5 recommendations:\u001b[0m\n",
      "['The History of Egypt Podcast', 'Renaissance English History Podcast: A Show About the Tudors', 'Trust and Believe with Shaun T', 'Made For This with Jennie Allen', 'The Ancients']\n",
      "\u001b[1mTop 5 recommendations' genre:\u001b[0m\n",
      "['History', 'History', 'Education', 'Religion & Spirituality', 'History']\n",
      "\u001b[1mSubscribers also subscribes to according to Apple Podcasts:\u001b[0m\n",
      "['Mythology', 'Our Fake History', 'The History Chicks', 'Myths and Legends', '1001 Heroes, Legends, Histories & Mysteries Podcast', 'The Classic Tales Podcast', 'The History of Ancient Greece', 'Northern Myths Podcast', 'Greeking Out from National Geographic Kids', 'Tales', 'Science Diction', 'Fictional', 'HISTORY This Week']\n",
      "\u001b[1m 0 out of 5 are accurate\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_recommendations(bow_cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
